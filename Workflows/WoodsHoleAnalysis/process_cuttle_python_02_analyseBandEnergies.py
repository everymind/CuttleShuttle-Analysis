# -*- coding: utf-8 -*-
"""
process_cuttle_python.py

Loads intermediate files generated by process_cuttle_python_02_genBandEnergies.py
Baseline and normalise band energies, pool across animals categorized by catch versus miss

@author: ARK/DK
"""
import os
import glob
import numpy as np
import matplotlib.pyplot as plt
import cv2
import datetime

### FUNCTIONS ###
def categorize_by_animal(TGB_files):
    all_animals_dict = {}
    # collect all canny counts and categorize by animal and type (catch vs miss)
    for TGB_file in TGB_files: 
        TGB_name = os.path.basename(TGB_file)
        TGB_animal = TGB_name.split("_")[1]
        TGB_type = TGB_name.split("_")[4]
        TS_bandEnergies = np.load(TGB_file)
        # extract power at each frequency band for every frame
        all_bands = range(TS_bandEnergies.shape[1])
        power_at_each_frequency = {key:[] for key in all_bands}
        for frame in TS_bandEnergies:
            for band in frame:
                i, = np.where(frame == band)[0]
                power_at_each_frequency[i].append(band)
        all_animals_dict.setdefault(TGB_animal,[]).append(power_at_each_frequency)
    return all_animals_dict

def categorize_by_animal_catchVmiss(TGB_files):
    catch_dict = {}
    miss_dict = {}
    # collect all canny counts and categorize by animal and type (catch vs miss)
    for TGB_file in TGB_files: 
        TGB_name = os.path.basename(TGB_file)
        TGB_animal = TGB_name.split("_")[1]
        TGB_type = TGB_name.split("_")[4]
        TS_bandEnergies = np.load(TGB_file)
        # extract power at each frequency band for every frame
        all_bands = range(TS_bandEnergies.shape[1])
        power_at_each_frequency = {key:[] for key in all_bands}
        for frame in TS_bandEnergies:
            for band in frame:
                i, = np.where(frame == band)[0]
                power_at_each_frequency[i].append(band)
        if TGB_type == "catch":
            catch_dict.setdefault(TGB_animal,[]).append(power_at_each_frequency)
        if TGB_type == "miss": 
            miss_dict.setdefault(TGB_animal,[]).append(power_at_each_frequency)
    return catch_dict, miss_dict

def baseSub_powerAtFreq(TS_dict, prey_type, baseline_len):
    baseSub_TS = {}
    # make baseline for each animal, catch vs miss
    for animal in TS_dict: 
        baseSub_TS[animal] = {}
        try:
            # baseline subtract each frequency during each trial
            allFreq_allTrials_baseSub = {}
            for i,trial in enumerate(TS_dict[animal]):
                for freq_band in trial:
                    baseSub_TS[animal][freq_band] = {}
                    this_freq_baseline = np.nanmean(TS_dict[animal][i][freq_band][0:baseline_len])
                    this_freq_basesubbed = [float(x-this_freq_baseline) for x in TS_dict[animal][i][freq_band]]
                    allFreq_allTrials_baseSub.setdefault(freq_band,[]).append(this_freq_basesubbed)
            for freq_band in allFreq_allTrials_baseSub:
                thisFreq_baseSub_mean_byFrame = np.nanmean(allFreq_allTrials_baseSub[freq_band], axis=0)
                thisFreq_baseSub_mean_bySess = np.nanmean(allFreq_allTrials_baseSub[freq_band])
                thisFreq_baseSub_std_byFrame = np.nanstd(allFreq_allTrials_baseSub[freq_band], axis=0, ddof=1)
                thisFreq_baseSub_std_bySess = np.nanstd(allFreq_allTrials_baseSub[freq_band], ddof=1)
                baseSub_TS[animal][freq_band]['trials'] = allFreq_allTrials_baseSub[freq_band]
                baseSub_TS[animal][freq_band]['mean frame'] = thisFreq_baseSub_mean_byFrame
                baseSub_TS[animal][freq_band]['mean session'] = thisFreq_baseSub_mean_bySess
                baseSub_TS[animal][freq_band]['std frame'] = thisFreq_baseSub_std_byFrame
                baseSub_TS[animal][freq_band]['std session'] = thisFreq_baseSub_std_bySess
        except Exception:
            print("{a} made no tentacle shots during {p} prey movement type".format(a=animal, p=prey_type))
    return baseSub_TS

### BEGIN ANALYSIS ###
# source data and output locations
data_folder = r'C:\Users\taunsquared\Dropbox\CuttleShuttle\analysis\WoodsHoleAnalysis'

# from data folder, collect all binary files with power-at-freq-band data
all_data = glob.glob(data_folder + os.sep + "*.npy")

# categorize tentacle shots according to prey movement
TGB_natural = []
TGB_patterned = []
TGB_causal = []
TGB_daily = {}
for TGB_file in all_data: 
    trial_date = os.path.basename(TGB_file).split('_')[2]
    sorted_by_session = TGB_daily.setdefault(trial_date,[]).append(TGB_file)
    trial_datetime = datetime.datetime.strptime(trial_date, '%Y-%m-%d')
    if trial_datetime < datetime.datetime(2014, 9, 13, 0, 0):
        TGB_natural.append(TGB_file)
    elif trial_datetime > datetime.datetime(2014, 10, 18, 0, 0):
        TGB_causal.append(TGB_file)
    else: 
        TGB_patterned.append(TGB_file)

# organize power-at-frequency-band data
# categorize daily sessions by animal
all_TS_daily = {}
all_catches_daily = {}
all_misses_daily = {}
for session_date in TGB_daily:
    all_TS_daily[session_date] = categorize_by_animal(TGB_daily[session_date])
    all_catches_daily[session_date], all_misses_daily[session_date] = categorize_by_animal_catchVmiss(TGB_daily[session_date])

# collect all power-at-frequency-band data and categorize by animal
all_TS = categorize_by_animal(all_data)
# collect all power-at-frequency-band data and categorize by animal and type (catch vs miss)
all_catches, all_misses = categorize_by_animal_catchVmiss(all_data)
# organize by prey type
all_raw = [all_catches, all_misses]
# time bin for moment tentacles go ballistic
TGB_bucket_raw = 180

########################################################
### ------ DATA NORMALIZATION/STANDARDIZATION ------ ###
########################################################
# baseline subtraction
baseline_frames = 150 #frames
# baseline subtract, all TS
dailyTS_baseSub = {}
for session_date in all_TS_daily:
    dailyTS_baseSub[session_date] = baseSub_powerAtFreq(all_TS_daily[session_date], 'all', baseline_frames)
allTS_baseSub = baseSub_powerAtFreq(all_TS, 'all', baseline_frames)
# baseline subtract, catch vs miss
dailyCatches_baseSub = {}
dailyMisses_baseSub = {}
for session_date in all_catches_daily:
    dailyCatches_baseSub[session_date] = baseSub_powerAtFreq(all_catches_daily[session_date], 'all', baseline_frames)
for session_date in all_misses_daily:
    dailyMisses_baseSub[session_date] = baseSub_powerAtFreq(all_misses_daily[session_date], 'all', baseline_frames)
allCatches_baseSub = baseSub_powerAtFreq(all_catches, 'all', baseline_frames)
allMisses_baseSub = baseSub_powerAtFreq(all_misses, 'all', baseline_frames)
# zscore each animal so that I can pool all trials into a "superanimal"

# zscore daily sessions for each animal to characterize session dynamics





# FIN